{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import shutil\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "from gensim import corpora, models, similarities\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_csv(\"model_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.zeros((len(model_data),150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_data)):\n",
    "    try:\n",
    "        t =np.hstack(model_data['past_3_judgmenent_vec'][i])\n",
    "        z = np.zeros(150-len(t), dtype=t.dtype)\n",
    "        vectors[i,:] = np.concatenate((t,z), axis=0)\n",
    "    except:\n",
    "        #print(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vec = pd.DataFrame(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vec.columns = [\"Jud_\"+str(x) for x in model_vec.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jud_0</th>\n",
       "      <th>Jud_1</th>\n",
       "      <th>Jud_2</th>\n",
       "      <th>Jud_3</th>\n",
       "      <th>Jud_4</th>\n",
       "      <th>Jud_5</th>\n",
       "      <th>Jud_6</th>\n",
       "      <th>Jud_7</th>\n",
       "      <th>Jud_8</th>\n",
       "      <th>Jud_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Jud_140</th>\n",
       "      <th>Jud_141</th>\n",
       "      <th>Jud_142</th>\n",
       "      <th>Jud_143</th>\n",
       "      <th>Jud_144</th>\n",
       "      <th>Jud_145</th>\n",
       "      <th>Jud_146</th>\n",
       "      <th>Jud_147</th>\n",
       "      <th>Jud_148</th>\n",
       "      <th>Jud_149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.709013</td>\n",
       "      <td>-0.487325</td>\n",
       "      <td>-1.056965</td>\n",
       "      <td>0.818804</td>\n",
       "      <td>-0.798959</td>\n",
       "      <td>1.001305</td>\n",
       "      <td>0.691063</td>\n",
       "      <td>0.193017</td>\n",
       "      <td>-0.804408</td>\n",
       "      <td>0.633024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058398</td>\n",
       "      <td>-1.668045</td>\n",
       "      <td>1.188825</td>\n",
       "      <td>0.788128</td>\n",
       "      <td>-1.885749</td>\n",
       "      <td>0.278859</td>\n",
       "      <td>-0.054479</td>\n",
       "      <td>-2.100279</td>\n",
       "      <td>1.034174</td>\n",
       "      <td>-1.231385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.174949</td>\n",
       "      <td>1.189296</td>\n",
       "      <td>-0.927771</td>\n",
       "      <td>0.257538</td>\n",
       "      <td>-0.298800</td>\n",
       "      <td>1.077674</td>\n",
       "      <td>-0.749863</td>\n",
       "      <td>-0.397366</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>-0.734707</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.108963</td>\n",
       "      <td>-1.870219</td>\n",
       "      <td>-1.867665</td>\n",
       "      <td>-0.657096</td>\n",
       "      <td>-2.281700</td>\n",
       "      <td>0.161461</td>\n",
       "      <td>-1.713752</td>\n",
       "      <td>-0.332595</td>\n",
       "      <td>1.556750</td>\n",
       "      <td>0.761622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.164659</td>\n",
       "      <td>-0.700158</td>\n",
       "      <td>-0.188421</td>\n",
       "      <td>-0.743105</td>\n",
       "      <td>0.681166</td>\n",
       "      <td>1.100095</td>\n",
       "      <td>0.149085</td>\n",
       "      <td>-0.199905</td>\n",
       "      <td>-0.679346</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266416</td>\n",
       "      <td>0.997326</td>\n",
       "      <td>-0.818119</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>-0.603537</td>\n",
       "      <td>1.588145</td>\n",
       "      <td>-0.283121</td>\n",
       "      <td>-0.996231</td>\n",
       "      <td>0.791162</td>\n",
       "      <td>0.468696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.584759</td>\n",
       "      <td>-1.071538</td>\n",
       "      <td>-2.043505</td>\n",
       "      <td>0.484414</td>\n",
       "      <td>0.151943</td>\n",
       "      <td>-0.082056</td>\n",
       "      <td>0.598946</td>\n",
       "      <td>-0.408808</td>\n",
       "      <td>0.550904</td>\n",
       "      <td>-0.182296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193194</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>-2.751466</td>\n",
       "      <td>-3.539840</td>\n",
       "      <td>-0.875378</td>\n",
       "      <td>0.360259</td>\n",
       "      <td>-0.244792</td>\n",
       "      <td>-0.170450</td>\n",
       "      <td>1.971528</td>\n",
       "      <td>1.845870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.368351</td>\n",
       "      <td>-1.080365</td>\n",
       "      <td>-3.706199</td>\n",
       "      <td>0.516378</td>\n",
       "      <td>-0.244941</td>\n",
       "      <td>1.347507</td>\n",
       "      <td>1.047686</td>\n",
       "      <td>1.546216</td>\n",
       "      <td>3.523230</td>\n",
       "      <td>-1.889053</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.688663</td>\n",
       "      <td>-4.064988</td>\n",
       "      <td>0.504453</td>\n",
       "      <td>-0.026259</td>\n",
       "      <td>0.093963</td>\n",
       "      <td>2.178278</td>\n",
       "      <td>-1.309577</td>\n",
       "      <td>-2.458808</td>\n",
       "      <td>1.464417</td>\n",
       "      <td>-0.882024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Jud_0     Jud_1     Jud_2     Jud_3     Jud_4     Jud_5     Jud_6  \\\n",
       "0 -0.709013 -0.487325 -1.056965  0.818804 -0.798959  1.001305  0.691063   \n",
       "1  0.174949  1.189296 -0.927771  0.257538 -0.298800  1.077674 -0.749863   \n",
       "2  0.164659 -0.700158 -0.188421 -0.743105  0.681166  1.100095  0.149085   \n",
       "3 -0.584759 -1.071538 -2.043505  0.484414  0.151943 -0.082056  0.598946   \n",
       "4 -1.368351 -1.080365 -3.706199  0.516378 -0.244941  1.347507  1.047686   \n",
       "\n",
       "      Jud_7     Jud_8     Jud_9  ...   Jud_140   Jud_141   Jud_142   Jud_143  \\\n",
       "0  0.193017 -0.804408  0.633024  ... -0.058398 -1.668045  1.188825  0.788128   \n",
       "1 -0.397366  0.008756 -0.734707  ... -2.108963 -1.870219 -1.867665 -0.657096   \n",
       "2 -0.199905 -0.679346  0.046218  ... -0.266416  0.997326 -0.818119  0.844203   \n",
       "3 -0.408808  0.550904 -0.182296  ...  0.193194  0.004010 -2.751466 -3.539840   \n",
       "4  1.546216  3.523230 -1.889053  ... -1.688663 -4.064988  0.504453 -0.026259   \n",
       "\n",
       "    Jud_144   Jud_145   Jud_146   Jud_147   Jud_148   Jud_149  \n",
       "0 -1.885749  0.278859 -0.054479 -2.100279  1.034174 -1.231385  \n",
       "1 -2.281700  0.161461 -1.713752 -0.332595  1.556750  0.761622  \n",
       "2 -0.603537  1.588145 -0.283121 -0.996231  0.791162  0.468696  \n",
       "3 -0.875378  0.360259 -0.244792 -0.170450  1.971528  1.845870  \n",
       "4  0.093963  2.178278 -1.309577 -2.458808  1.464417 -0.882024  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(model_vec, model_data['harsh'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:15:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve on the test data = 0.6361\n",
      "Accuracy test data = 0.7379\n",
      "F1 Score test data = 0.26\n"
     ]
    }
   ],
   "source": [
    "print(f'Area under the ROC curve on the test data = {round(metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1]), 4)}')\n",
    "print(f'Accuracy test data = {round(metrics.accuracy_score(y_test, model.predict(X_test)), 4)}')\n",
    "print(f'F1 Score test data = {round(metrics.f1_score(y_test, model.predict(X_test)), 4)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict_proba(X_test)[:,1]\n",
    "y_preds = np.where(y_preds>0.38,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7185638383513122"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.350185873605948"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([5066, 1145]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_preds,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = metrics.precision_recall_curve(y_test, model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0038346 , 0.00475329, 0.00499453, ..., 0.97092146, 0.97596985,\n",
       "       0.97917545], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_preds)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '2-class Precision-Recall curve: AP=0.30')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = plot_precision_recall_curve(model, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_vectors = np.zeros((len(model_data),50))\n",
    "for i in range(len(model_data)):\n",
    "    try:\n",
    "        t =np.hstack(model_data['facts_vector'][i])\n",
    "        z = np.zeros(50-len(t), dtype=t.dtype)\n",
    "        fact_vectors[i,:] = np.concatenate((t,z), axis=0)\n",
    "    except:\n",
    "        #print(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_vectors = pd.DataFrame(fact_vectors)\n",
    "\n",
    "fact_vectors.columns = [\"fact_emb_\"+str(x) for x in fact_vectors.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_emb_0</th>\n",
       "      <th>fact_emb_1</th>\n",
       "      <th>fact_emb_2</th>\n",
       "      <th>fact_emb_3</th>\n",
       "      <th>fact_emb_4</th>\n",
       "      <th>fact_emb_5</th>\n",
       "      <th>fact_emb_6</th>\n",
       "      <th>fact_emb_7</th>\n",
       "      <th>fact_emb_8</th>\n",
       "      <th>fact_emb_9</th>\n",
       "      <th>...</th>\n",
       "      <th>fact_emb_40</th>\n",
       "      <th>fact_emb_41</th>\n",
       "      <th>fact_emb_42</th>\n",
       "      <th>fact_emb_43</th>\n",
       "      <th>fact_emb_44</th>\n",
       "      <th>fact_emb_45</th>\n",
       "      <th>fact_emb_46</th>\n",
       "      <th>fact_emb_47</th>\n",
       "      <th>fact_emb_48</th>\n",
       "      <th>fact_emb_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.077379</td>\n",
       "      <td>-1.153064</td>\n",
       "      <td>-1.175251</td>\n",
       "      <td>3.510302</td>\n",
       "      <td>2.280033</td>\n",
       "      <td>-0.964784</td>\n",
       "      <td>-2.382688</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.204327</td>\n",
       "      <td>-2.628231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.275725</td>\n",
       "      <td>0.749361</td>\n",
       "      <td>-1.236280</td>\n",
       "      <td>-2.968399</td>\n",
       "      <td>2.563970</td>\n",
       "      <td>0.277645</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>1.128461</td>\n",
       "      <td>1.312803</td>\n",
       "      <td>-2.323720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.396037</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>-2.792444</td>\n",
       "      <td>2.946386</td>\n",
       "      <td>0.100429</td>\n",
       "      <td>-0.727175</td>\n",
       "      <td>-1.564026</td>\n",
       "      <td>-0.456334</td>\n",
       "      <td>-1.848460</td>\n",
       "      <td>-0.769046</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.333027</td>\n",
       "      <td>-0.134554</td>\n",
       "      <td>-1.007138</td>\n",
       "      <td>-2.717016</td>\n",
       "      <td>1.598934</td>\n",
       "      <td>0.472292</td>\n",
       "      <td>0.188702</td>\n",
       "      <td>-1.014126</td>\n",
       "      <td>2.751991</td>\n",
       "      <td>-1.364089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568689</td>\n",
       "      <td>-2.242065</td>\n",
       "      <td>-1.487257</td>\n",
       "      <td>2.021035</td>\n",
       "      <td>0.655754</td>\n",
       "      <td>-0.120980</td>\n",
       "      <td>-3.916295</td>\n",
       "      <td>-0.261597</td>\n",
       "      <td>0.625245</td>\n",
       "      <td>-2.353674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.772396</td>\n",
       "      <td>-0.872905</td>\n",
       "      <td>-1.230478</td>\n",
       "      <td>-3.404712</td>\n",
       "      <td>3.449621</td>\n",
       "      <td>0.274740</td>\n",
       "      <td>-1.984469</td>\n",
       "      <td>-1.442404</td>\n",
       "      <td>-0.851224</td>\n",
       "      <td>1.276552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.174298</td>\n",
       "      <td>-0.170248</td>\n",
       "      <td>-0.662774</td>\n",
       "      <td>0.528286</td>\n",
       "      <td>-0.055306</td>\n",
       "      <td>-0.349290</td>\n",
       "      <td>-3.064025</td>\n",
       "      <td>1.223578</td>\n",
       "      <td>-0.028150</td>\n",
       "      <td>-0.338014</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.101452</td>\n",
       "      <td>-0.598086</td>\n",
       "      <td>0.092205</td>\n",
       "      <td>-1.674878</td>\n",
       "      <td>0.914630</td>\n",
       "      <td>-0.420852</td>\n",
       "      <td>-0.492278</td>\n",
       "      <td>-2.264972</td>\n",
       "      <td>3.601571</td>\n",
       "      <td>0.398855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.989488</td>\n",
       "      <td>-1.219482</td>\n",
       "      <td>-1.423161</td>\n",
       "      <td>3.738959</td>\n",
       "      <td>5.863144</td>\n",
       "      <td>-1.498037</td>\n",
       "      <td>1.876165</td>\n",
       "      <td>-1.304972</td>\n",
       "      <td>-3.018544</td>\n",
       "      <td>1.998867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678608</td>\n",
       "      <td>-0.265010</td>\n",
       "      <td>-0.684879</td>\n",
       "      <td>1.839812</td>\n",
       "      <td>3.059956</td>\n",
       "      <td>1.365849</td>\n",
       "      <td>3.039275</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>0.342930</td>\n",
       "      <td>3.686197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fact_emb_0  fact_emb_1  fact_emb_2  fact_emb_3  fact_emb_4  fact_emb_5  \\\n",
       "0   -0.077379   -1.153064   -1.175251    3.510302    2.280033   -0.964784   \n",
       "1    0.396037    0.152778   -2.792444    2.946386    0.100429   -0.727175   \n",
       "2    0.568689   -2.242065   -1.487257    2.021035    0.655754   -0.120980   \n",
       "3    0.174298   -0.170248   -0.662774    0.528286   -0.055306   -0.349290   \n",
       "4   -1.989488   -1.219482   -1.423161    3.738959    5.863144   -1.498037   \n",
       "\n",
       "   fact_emb_6  fact_emb_7  fact_emb_8  fact_emb_9  ...  fact_emb_40  \\\n",
       "0   -2.382688    0.655629    0.204327   -2.628231  ...     1.275725   \n",
       "1   -1.564026   -0.456334   -1.848460   -0.769046  ...    -1.333027   \n",
       "2   -3.916295   -0.261597    0.625245   -2.353674  ...    -0.772396   \n",
       "3   -3.064025    1.223578   -0.028150   -0.338014  ...    -3.101452   \n",
       "4    1.876165   -1.304972   -3.018544    1.998867  ...    -0.678608   \n",
       "\n",
       "   fact_emb_41  fact_emb_42  fact_emb_43  fact_emb_44  fact_emb_45  \\\n",
       "0     0.749361    -1.236280    -2.968399     2.563970     0.277645   \n",
       "1    -0.134554    -1.007138    -2.717016     1.598934     0.472292   \n",
       "2    -0.872905    -1.230478    -3.404712     3.449621     0.274740   \n",
       "3    -0.598086     0.092205    -1.674878     0.914630    -0.420852   \n",
       "4    -0.265010    -0.684879     1.839812     3.059956     1.365849   \n",
       "\n",
       "   fact_emb_46  fact_emb_47  fact_emb_48  fact_emb_49  \n",
       "0     0.018563     1.128461     1.312803    -2.323720  \n",
       "1     0.188702    -1.014126     2.751991    -1.364089  \n",
       "2    -1.984469    -1.442404    -0.851224     1.276552  \n",
       "3    -0.492278    -2.264972     3.601571     0.398855  \n",
       "4     3.039275    -0.088997     0.342930     3.686197  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31052, 50)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_stage_model_data = fact_vectors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_judgement_preds = model.predict_proba(model_vec)[:,1]\n",
    "model_judgement_preds = np.where(model_judgement_preds>0.38,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_stage_model_data['judgement_pred'] = model_judgement_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_stage_model_data.index = model_data.file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>fact_emb_0</th>\n",
       "      <th>fact_emb_1</th>\n",
       "      <th>fact_emb_2</th>\n",
       "      <th>fact_emb_3</th>\n",
       "      <th>fact_emb_4</th>\n",
       "      <th>fact_emb_5</th>\n",
       "      <th>fact_emb_6</th>\n",
       "      <th>fact_emb_7</th>\n",
       "      <th>fact_emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>fact_emb_41</th>\n",
       "      <th>fact_emb_42</th>\n",
       "      <th>fact_emb_43</th>\n",
       "      <th>fact_emb_44</th>\n",
       "      <th>fact_emb_45</th>\n",
       "      <th>fact_emb_46</th>\n",
       "      <th>fact_emb_47</th>\n",
       "      <th>fact_emb_48</th>\n",
       "      <th>fact_emb_49</th>\n",
       "      <th>judgement_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34613760</td>\n",
       "      <td>-0.077379</td>\n",
       "      <td>-1.153064</td>\n",
       "      <td>-1.175251</td>\n",
       "      <td>3.510302</td>\n",
       "      <td>2.280033</td>\n",
       "      <td>-0.964784</td>\n",
       "      <td>-2.382688</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.204327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749361</td>\n",
       "      <td>-1.236280</td>\n",
       "      <td>-2.968399</td>\n",
       "      <td>2.563970</td>\n",
       "      <td>0.277645</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>1.128461</td>\n",
       "      <td>1.312803</td>\n",
       "      <td>-2.323720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57145403</td>\n",
       "      <td>0.396037</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>-2.792444</td>\n",
       "      <td>2.946386</td>\n",
       "      <td>0.100429</td>\n",
       "      <td>-0.727175</td>\n",
       "      <td>-1.564026</td>\n",
       "      <td>-0.456334</td>\n",
       "      <td>-1.848460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134554</td>\n",
       "      <td>-1.007138</td>\n",
       "      <td>-2.717016</td>\n",
       "      <td>1.598934</td>\n",
       "      <td>0.472292</td>\n",
       "      <td>0.188702</td>\n",
       "      <td>-1.014126</td>\n",
       "      <td>2.751991</td>\n",
       "      <td>-1.364089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33817559</td>\n",
       "      <td>0.568689</td>\n",
       "      <td>-2.242065</td>\n",
       "      <td>-1.487257</td>\n",
       "      <td>2.021035</td>\n",
       "      <td>0.655754</td>\n",
       "      <td>-0.120980</td>\n",
       "      <td>-3.916295</td>\n",
       "      <td>-0.261597</td>\n",
       "      <td>0.625245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.872905</td>\n",
       "      <td>-1.230478</td>\n",
       "      <td>-3.404712</td>\n",
       "      <td>3.449621</td>\n",
       "      <td>0.274740</td>\n",
       "      <td>-1.984469</td>\n",
       "      <td>-1.442404</td>\n",
       "      <td>-0.851224</td>\n",
       "      <td>1.276552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33863247</td>\n",
       "      <td>0.174298</td>\n",
       "      <td>-0.170248</td>\n",
       "      <td>-0.662774</td>\n",
       "      <td>0.528286</td>\n",
       "      <td>-0.055306</td>\n",
       "      <td>-0.349290</td>\n",
       "      <td>-3.064025</td>\n",
       "      <td>1.223578</td>\n",
       "      <td>-0.028150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.598086</td>\n",
       "      <td>0.092205</td>\n",
       "      <td>-1.674878</td>\n",
       "      <td>0.914630</td>\n",
       "      <td>-0.420852</td>\n",
       "      <td>-0.492278</td>\n",
       "      <td>-2.264972</td>\n",
       "      <td>3.601571</td>\n",
       "      <td>0.398855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27729615</td>\n",
       "      <td>-1.989488</td>\n",
       "      <td>-1.219482</td>\n",
       "      <td>-1.423161</td>\n",
       "      <td>3.738959</td>\n",
       "      <td>5.863144</td>\n",
       "      <td>-1.498037</td>\n",
       "      <td>1.876165</td>\n",
       "      <td>-1.304972</td>\n",
       "      <td>-3.018544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265010</td>\n",
       "      <td>-0.684879</td>\n",
       "      <td>1.839812</td>\n",
       "      <td>3.059956</td>\n",
       "      <td>1.365849</td>\n",
       "      <td>3.039275</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>0.342930</td>\n",
       "      <td>3.686197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  fact_emb_0  fact_emb_1  fact_emb_2  fact_emb_3  fact_emb_4  \\\n",
       "0   34613760   -0.077379   -1.153064   -1.175251    3.510302    2.280033   \n",
       "1   57145403    0.396037    0.152778   -2.792444    2.946386    0.100429   \n",
       "2   33817559    0.568689   -2.242065   -1.487257    2.021035    0.655754   \n",
       "3   33863247    0.174298   -0.170248   -0.662774    0.528286   -0.055306   \n",
       "4   27729615   -1.989488   -1.219482   -1.423161    3.738959    5.863144   \n",
       "\n",
       "   fact_emb_5  fact_emb_6  fact_emb_7  fact_emb_8  ...  fact_emb_41  \\\n",
       "0   -0.964784   -2.382688    0.655629    0.204327  ...     0.749361   \n",
       "1   -0.727175   -1.564026   -0.456334   -1.848460  ...    -0.134554   \n",
       "2   -0.120980   -3.916295   -0.261597    0.625245  ...    -0.872905   \n",
       "3   -0.349290   -3.064025    1.223578   -0.028150  ...    -0.598086   \n",
       "4   -1.498037    1.876165   -1.304972   -3.018544  ...    -0.265010   \n",
       "\n",
       "   fact_emb_42  fact_emb_43  fact_emb_44  fact_emb_45  fact_emb_46  \\\n",
       "0    -1.236280    -2.968399     2.563970     0.277645     0.018563   \n",
       "1    -1.007138    -2.717016     1.598934     0.472292     0.188702   \n",
       "2    -1.230478    -3.404712     3.449621     0.274740    -1.984469   \n",
       "3     0.092205    -1.674878     0.914630    -0.420852    -0.492278   \n",
       "4    -0.684879     1.839812     3.059956     1.365849     3.039275   \n",
       "\n",
       "   fact_emb_47  fact_emb_48  fact_emb_49  judgement_pred  \n",
       "0     1.128461     1.312803    -2.323720               0  \n",
       "1    -1.014126     2.751991    -1.364089               1  \n",
       "2    -1.442404    -0.851224     1.276552               0  \n",
       "3    -2.264972     3.601571     0.398855               0  \n",
       "4    -0.088997     0.342930     3.686197               1  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_stage_model_data.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_stage_model_data = pd.merge(second_stage_model_data,model_data[['file_name','gov_pet','gov_resp','crime_rate']].drop_duplicates(),on='file_name',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31052, 55)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_stage_model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>fact_emb_0</th>\n",
       "      <th>fact_emb_1</th>\n",
       "      <th>fact_emb_2</th>\n",
       "      <th>fact_emb_3</th>\n",
       "      <th>fact_emb_4</th>\n",
       "      <th>fact_emb_5</th>\n",
       "      <th>fact_emb_6</th>\n",
       "      <th>fact_emb_7</th>\n",
       "      <th>fact_emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>fact_emb_44</th>\n",
       "      <th>fact_emb_45</th>\n",
       "      <th>fact_emb_46</th>\n",
       "      <th>fact_emb_47</th>\n",
       "      <th>fact_emb_48</th>\n",
       "      <th>fact_emb_49</th>\n",
       "      <th>judgement_pred</th>\n",
       "      <th>gov_pet</th>\n",
       "      <th>gov_resp</th>\n",
       "      <th>crime_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34613760</td>\n",
       "      <td>-0.077379</td>\n",
       "      <td>-1.153064</td>\n",
       "      <td>-1.175251</td>\n",
       "      <td>3.510302</td>\n",
       "      <td>2.280033</td>\n",
       "      <td>-0.964784</td>\n",
       "      <td>-2.382688</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.204327</td>\n",
       "      <td>...</td>\n",
       "      <td>2.563970</td>\n",
       "      <td>0.277645</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>1.128461</td>\n",
       "      <td>1.312803</td>\n",
       "      <td>-2.323720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57145403</td>\n",
       "      <td>0.396037</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>-2.792444</td>\n",
       "      <td>2.946386</td>\n",
       "      <td>0.100429</td>\n",
       "      <td>-0.727175</td>\n",
       "      <td>-1.564026</td>\n",
       "      <td>-0.456334</td>\n",
       "      <td>-1.848460</td>\n",
       "      <td>...</td>\n",
       "      <td>1.598934</td>\n",
       "      <td>0.472292</td>\n",
       "      <td>0.188702</td>\n",
       "      <td>-1.014126</td>\n",
       "      <td>2.751991</td>\n",
       "      <td>-1.364089</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33817559</td>\n",
       "      <td>0.568689</td>\n",
       "      <td>-2.242065</td>\n",
       "      <td>-1.487257</td>\n",
       "      <td>2.021035</td>\n",
       "      <td>0.655754</td>\n",
       "      <td>-0.120980</td>\n",
       "      <td>-3.916295</td>\n",
       "      <td>-0.261597</td>\n",
       "      <td>0.625245</td>\n",
       "      <td>...</td>\n",
       "      <td>3.449621</td>\n",
       "      <td>0.274740</td>\n",
       "      <td>-1.984469</td>\n",
       "      <td>-1.442404</td>\n",
       "      <td>-0.851224</td>\n",
       "      <td>1.276552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33863247</td>\n",
       "      <td>0.174298</td>\n",
       "      <td>-0.170248</td>\n",
       "      <td>-0.662774</td>\n",
       "      <td>0.528286</td>\n",
       "      <td>-0.055306</td>\n",
       "      <td>-0.349290</td>\n",
       "      <td>-3.064025</td>\n",
       "      <td>1.223578</td>\n",
       "      <td>-0.028150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914630</td>\n",
       "      <td>-0.420852</td>\n",
       "      <td>-0.492278</td>\n",
       "      <td>-2.264972</td>\n",
       "      <td>3.601571</td>\n",
       "      <td>0.398855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27729615</td>\n",
       "      <td>-1.989488</td>\n",
       "      <td>-1.219482</td>\n",
       "      <td>-1.423161</td>\n",
       "      <td>3.738959</td>\n",
       "      <td>5.863144</td>\n",
       "      <td>-1.498037</td>\n",
       "      <td>1.876165</td>\n",
       "      <td>-1.304972</td>\n",
       "      <td>-3.018544</td>\n",
       "      <td>...</td>\n",
       "      <td>3.059956</td>\n",
       "      <td>1.365849</td>\n",
       "      <td>3.039275</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>0.342930</td>\n",
       "      <td>3.686197</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  fact_emb_0  fact_emb_1  fact_emb_2  fact_emb_3  fact_emb_4  \\\n",
       "0   34613760   -0.077379   -1.153064   -1.175251    3.510302    2.280033   \n",
       "1   57145403    0.396037    0.152778   -2.792444    2.946386    0.100429   \n",
       "2   33817559    0.568689   -2.242065   -1.487257    2.021035    0.655754   \n",
       "3   33863247    0.174298   -0.170248   -0.662774    0.528286   -0.055306   \n",
       "4   27729615   -1.989488   -1.219482   -1.423161    3.738959    5.863144   \n",
       "\n",
       "   fact_emb_5  fact_emb_6  fact_emb_7  fact_emb_8  ...  fact_emb_44  \\\n",
       "0   -0.964784   -2.382688    0.655629    0.204327  ...     2.563970   \n",
       "1   -0.727175   -1.564026   -0.456334   -1.848460  ...     1.598934   \n",
       "2   -0.120980   -3.916295   -0.261597    0.625245  ...     3.449621   \n",
       "3   -0.349290   -3.064025    1.223578   -0.028150  ...     0.914630   \n",
       "4   -1.498037    1.876165   -1.304972   -3.018544  ...     3.059956   \n",
       "\n",
       "   fact_emb_45  fact_emb_46  fact_emb_47  fact_emb_48  fact_emb_49  \\\n",
       "0     0.277645     0.018563     1.128461     1.312803    -2.323720   \n",
       "1     0.472292     0.188702    -1.014126     2.751991    -1.364089   \n",
       "2     0.274740    -1.984469    -1.442404    -0.851224     1.276552   \n",
       "3    -0.420852    -0.492278    -2.264972     3.601571     0.398855   \n",
       "4     1.365849     3.039275    -0.088997     0.342930     3.686197   \n",
       "\n",
       "   judgement_pred  gov_pet  gov_resp  crime_rate  \n",
       "0               0      0.0       1.0        92.5  \n",
       "1               1      0.0       0.0        92.5  \n",
       "2               0      0.0       1.0        92.5  \n",
       "3               0      0.0       1.0        92.5  \n",
       "4               1      0.0       0.0        92.5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_stage_model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['file_name','crime_rate']\n",
    "\n",
    "X = second_stage_model_data.drop(columns=drop_cols)\n",
    "y = second_stage_model_data['crime_rate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5289737625933595"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "form = \"crime_rate~\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(second_stage_model_data.columns)-1):\n",
    "    if i == len(second_stage_model_data.columns)-2:\n",
    "        form = form +second_stage_model_data.columns[i]\n",
    "    else:\n",
    "        form = form +second_stage_model_data.columns[i]+\"+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crime_rate~fact_emb_0+fact_emb_1+fact_emb_2+fact_emb_3+fact_emb_4+fact_emb_5+fact_emb_6+fact_emb_7+fact_emb_8+fact_emb_9+fact_emb_10+fact_emb_11+fact_emb_12+fact_emb_13+fact_emb_14+fact_emb_15+fact_emb_16+fact_emb_17+fact_emb_18+fact_emb_19+fact_emb_20+fact_emb_21+fact_emb_22+fact_emb_23+fact_emb_24+fact_emb_25+fact_emb_26+fact_emb_27+fact_emb_28+fact_emb_29+fact_emb_30+fact_emb_31+fact_emb_32+fact_emb_33+fact_emb_34+fact_emb_35+fact_emb_36+fact_emb_37+fact_emb_38+fact_emb_39+fact_emb_40+fact_emb_41+fact_emb_42+fact_emb_43+fact_emb_44+fact_emb_45+fact_emb_46+fact_emb_47+fact_emb_48+fact_emb_49+judgement_pred+gov_pet+gov_resp\n"
     ]
    }
   ],
   "source": [
    "print(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = sm.ols(formula=form, data=second_stage_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted1 = reg.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             crime_rate   R-squared:                       0.523\n",
      "Model:                            OLS   Adj. R-squared:                  0.522\n",
      "Method:                 Least Squares   F-statistic:                     640.3\n",
      "Date:                Thu, 13 May 2021   Prob (F-statistic):               0.00\n",
      "Time:                        07:32:28   Log-Likelihood:            -1.2794e+05\n",
      "No. Observations:               31052   AIC:                         2.560e+05\n",
      "Df Residuals:                   30998   BIC:                         2.564e+05\n",
      "Df Model:                          53                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         39.1830      0.679     57.745      0.000      37.853      40.513\n",
      "fact_emb_0         1.3805      0.141      9.784      0.000       1.104       1.657\n",
      "fact_emb_1         0.9236      0.131      7.035      0.000       0.666       1.181\n",
      "fact_emb_2         2.7169      0.135     20.089      0.000       2.452       2.982\n",
      "fact_emb_3         0.8080      0.136      5.921      0.000       0.541       1.076\n",
      "fact_emb_4         3.6394      0.141     25.758      0.000       3.362       3.916\n",
      "fact_emb_5        -2.3201      0.139    -16.654      0.000      -2.593      -2.047\n",
      "fact_emb_6        -3.8188      0.132    -28.955      0.000      -4.077      -3.560\n",
      "fact_emb_7        -0.3133      0.145     -2.163      0.031      -0.597      -0.029\n",
      "fact_emb_8         2.5142      0.147     17.145      0.000       2.227       2.802\n",
      "fact_emb_9         0.6540      0.147      4.459      0.000       0.366       0.941\n",
      "fact_emb_10       -0.7000      0.130     -5.374      0.000      -0.955      -0.445\n",
      "fact_emb_11        0.2434      0.136      1.790      0.074      -0.023       0.510\n",
      "fact_emb_12       -0.0169      0.127     -0.133      0.894      -0.266       0.232\n",
      "fact_emb_13        1.3964      0.144      9.709      0.000       1.115       1.678\n",
      "fact_emb_14        1.6550      0.128     12.977      0.000       1.405       1.905\n",
      "fact_emb_15        0.6081      0.142      4.279      0.000       0.330       0.887\n",
      "fact_emb_16        3.5277      0.131     26.942      0.000       3.271       3.784\n",
      "fact_emb_17        0.0664      0.142      0.468      0.640      -0.212       0.345\n",
      "fact_emb_18       -0.3055      0.153     -1.994      0.046      -0.606      -0.005\n",
      "fact_emb_19        2.7918      0.135     20.732      0.000       2.528       3.056\n",
      "fact_emb_20        1.4282      0.140     10.229      0.000       1.155       1.702\n",
      "fact_emb_21        2.8626      0.146     19.661      0.000       2.577       3.148\n",
      "fact_emb_22       -2.2179      0.148    -14.951      0.000      -2.509      -1.927\n",
      "fact_emb_23        3.3456      0.134     25.030      0.000       3.084       3.608\n",
      "fact_emb_24       -3.4239      0.128    -26.664      0.000      -3.676      -3.172\n",
      "fact_emb_25        0.1387      0.130      1.067      0.286      -0.116       0.393\n",
      "fact_emb_26        1.6702      0.152     11.024      0.000       1.373       1.967\n",
      "fact_emb_27       -1.1610      0.136     -8.555      0.000      -1.427      -0.895\n",
      "fact_emb_28       -0.5444      0.140     -3.886      0.000      -0.819      -0.270\n",
      "fact_emb_29        1.4656      0.156      9.411      0.000       1.160       1.771\n",
      "fact_emb_30       -0.7130      0.129     -5.512      0.000      -0.967      -0.459\n",
      "fact_emb_31        2.8892      0.138     20.916      0.000       2.618       3.160\n",
      "fact_emb_32       -2.0156      0.138    -14.598      0.000      -2.286      -1.745\n",
      "fact_emb_33       -0.6223      0.143     -4.354      0.000      -0.902      -0.342\n",
      "fact_emb_34        0.9937      0.144      6.889      0.000       0.711       1.276\n",
      "fact_emb_35       -0.5492      0.136     -4.032      0.000      -0.816      -0.282\n",
      "fact_emb_36       -0.0358      0.133     -0.270      0.787      -0.296       0.225\n",
      "fact_emb_37       -0.8641      0.141     -6.132      0.000      -1.140      -0.588\n",
      "fact_emb_38        0.9607      0.136      7.060      0.000       0.694       1.227\n",
      "fact_emb_39       -5.2920      0.129    -41.089      0.000      -5.544      -5.040\n",
      "fact_emb_40        0.2157      0.134      1.603      0.109      -0.048       0.479\n",
      "fact_emb_41        2.2532      0.143     15.720      0.000       1.972       2.534\n",
      "fact_emb_42        3.3180      0.132     25.075      0.000       3.059       3.577\n",
      "fact_emb_43        1.6478      0.141     11.691      0.000       1.372       1.924\n",
      "fact_emb_44       -1.3513      0.148     -9.147      0.000      -1.641      -1.062\n",
      "fact_emb_45        1.5694      0.153     10.268      0.000       1.270       1.869\n",
      "fact_emb_46       -2.5222      0.147    -17.178      0.000      -2.810      -2.234\n",
      "fact_emb_47       -0.6458      0.150     -4.310      0.000      -0.940      -0.352\n",
      "fact_emb_48        0.1827      0.138      1.322      0.186      -0.088       0.453\n",
      "fact_emb_49       -0.5064      0.146     -3.472      0.001      -0.792      -0.221\n",
      "judgement_pred     1.2144      0.210      5.772      0.000       0.802       1.627\n",
      "gov_pet           -9.7074      1.309     -7.415      0.000     -12.273      -7.142\n",
      "gov_resp          -2.5898      0.221    -11.737      0.000      -3.022      -2.157\n",
      "==============================================================================\n",
      "Omnibus:                     4493.531   Durbin-Watson:                   0.620\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9403.198\n",
      "Skew:                           0.880   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.041   Cond. No.                         55.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(fitted1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = second_stage_model_data.judgement_pred.values\n",
    "y = second_stage_model_data.crime_rate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_stage_model_data['Predicted_Crime_rate'] = fitted1.predict(second_stage_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>fact_emb_0</th>\n",
       "      <th>fact_emb_1</th>\n",
       "      <th>fact_emb_2</th>\n",
       "      <th>fact_emb_3</th>\n",
       "      <th>fact_emb_4</th>\n",
       "      <th>fact_emb_5</th>\n",
       "      <th>fact_emb_6</th>\n",
       "      <th>fact_emb_7</th>\n",
       "      <th>fact_emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>fact_emb_45</th>\n",
       "      <th>fact_emb_46</th>\n",
       "      <th>fact_emb_47</th>\n",
       "      <th>fact_emb_48</th>\n",
       "      <th>fact_emb_49</th>\n",
       "      <th>judgement_pred</th>\n",
       "      <th>gov_pet</th>\n",
       "      <th>gov_resp</th>\n",
       "      <th>crime_rate</th>\n",
       "      <th>Predicted_Crime_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34613760</td>\n",
       "      <td>-0.077379</td>\n",
       "      <td>-1.153064</td>\n",
       "      <td>-1.175251</td>\n",
       "      <td>3.510302</td>\n",
       "      <td>2.280033</td>\n",
       "      <td>-0.964784</td>\n",
       "      <td>-2.382688</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.204327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277645</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>1.128461</td>\n",
       "      <td>1.312803</td>\n",
       "      <td>-2.323720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>60.585622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57145403</td>\n",
       "      <td>0.396037</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>-2.792444</td>\n",
       "      <td>2.946386</td>\n",
       "      <td>0.100429</td>\n",
       "      <td>-0.727175</td>\n",
       "      <td>-1.564026</td>\n",
       "      <td>-0.456334</td>\n",
       "      <td>-1.848460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472292</td>\n",
       "      <td>0.188702</td>\n",
       "      <td>-1.014126</td>\n",
       "      <td>2.751991</td>\n",
       "      <td>-1.364089</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>74.963059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33817559</td>\n",
       "      <td>0.568689</td>\n",
       "      <td>-2.242065</td>\n",
       "      <td>-1.487257</td>\n",
       "      <td>2.021035</td>\n",
       "      <td>0.655754</td>\n",
       "      <td>-0.120980</td>\n",
       "      <td>-3.916295</td>\n",
       "      <td>-0.261597</td>\n",
       "      <td>0.625245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274740</td>\n",
       "      <td>-1.984469</td>\n",
       "      <td>-1.442404</td>\n",
       "      <td>-0.851224</td>\n",
       "      <td>1.276552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>45.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33863247</td>\n",
       "      <td>0.174298</td>\n",
       "      <td>-0.170248</td>\n",
       "      <td>-0.662774</td>\n",
       "      <td>0.528286</td>\n",
       "      <td>-0.055306</td>\n",
       "      <td>-0.349290</td>\n",
       "      <td>-3.064025</td>\n",
       "      <td>1.223578</td>\n",
       "      <td>-0.028150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.420852</td>\n",
       "      <td>-0.492278</td>\n",
       "      <td>-2.264972</td>\n",
       "      <td>3.601571</td>\n",
       "      <td>0.398855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>69.290646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27729615</td>\n",
       "      <td>-1.989488</td>\n",
       "      <td>-1.219482</td>\n",
       "      <td>-1.423161</td>\n",
       "      <td>3.738959</td>\n",
       "      <td>5.863144</td>\n",
       "      <td>-1.498037</td>\n",
       "      <td>1.876165</td>\n",
       "      <td>-1.304972</td>\n",
       "      <td>-3.018544</td>\n",
       "      <td>...</td>\n",
       "      <td>1.365849</td>\n",
       "      <td>3.039275</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>0.342930</td>\n",
       "      <td>3.686197</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>26.117052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  fact_emb_0  fact_emb_1  fact_emb_2  fact_emb_3  fact_emb_4  \\\n",
       "0   34613760   -0.077379   -1.153064   -1.175251    3.510302    2.280033   \n",
       "1   57145403    0.396037    0.152778   -2.792444    2.946386    0.100429   \n",
       "2   33817559    0.568689   -2.242065   -1.487257    2.021035    0.655754   \n",
       "3   33863247    0.174298   -0.170248   -0.662774    0.528286   -0.055306   \n",
       "4   27729615   -1.989488   -1.219482   -1.423161    3.738959    5.863144   \n",
       "\n",
       "   fact_emb_5  fact_emb_6  fact_emb_7  fact_emb_8  ...  fact_emb_45  \\\n",
       "0   -0.964784   -2.382688    0.655629    0.204327  ...     0.277645   \n",
       "1   -0.727175   -1.564026   -0.456334   -1.848460  ...     0.472292   \n",
       "2   -0.120980   -3.916295   -0.261597    0.625245  ...     0.274740   \n",
       "3   -0.349290   -3.064025    1.223578   -0.028150  ...    -0.420852   \n",
       "4   -1.498037    1.876165   -1.304972   -3.018544  ...     1.365849   \n",
       "\n",
       "   fact_emb_46  fact_emb_47  fact_emb_48  fact_emb_49  judgement_pred  \\\n",
       "0     0.018563     1.128461     1.312803    -2.323720               0   \n",
       "1     0.188702    -1.014126     2.751991    -1.364089               1   \n",
       "2    -1.984469    -1.442404    -0.851224     1.276552               0   \n",
       "3    -0.492278    -2.264972     3.601571     0.398855               0   \n",
       "4     3.039275    -0.088997     0.342930     3.686197               1   \n",
       "\n",
       "   gov_pet  gov_resp  crime_rate  Predicted_Crime_rate  \n",
       "0      0.0       1.0        92.5             60.585622  \n",
       "1      0.0       0.0        92.5             74.963059  \n",
       "2      0.0       1.0        92.5             45.487100  \n",
       "3      0.0       1.0        92.5             69.290646  \n",
       "4      0.0       0.0        92.5             26.117052  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_stage_model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jud_0</th>\n",
       "      <th>Jud_1</th>\n",
       "      <th>Jud_2</th>\n",
       "      <th>Jud_3</th>\n",
       "      <th>Jud_4</th>\n",
       "      <th>Jud_5</th>\n",
       "      <th>Jud_6</th>\n",
       "      <th>Jud_7</th>\n",
       "      <th>Jud_8</th>\n",
       "      <th>Jud_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Jud_141</th>\n",
       "      <th>Jud_142</th>\n",
       "      <th>Jud_143</th>\n",
       "      <th>Jud_144</th>\n",
       "      <th>Jud_145</th>\n",
       "      <th>Jud_146</th>\n",
       "      <th>Jud_147</th>\n",
       "      <th>Jud_148</th>\n",
       "      <th>Jud_149</th>\n",
       "      <th>harsh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.709013</td>\n",
       "      <td>-0.487325</td>\n",
       "      <td>-1.056965</td>\n",
       "      <td>0.818804</td>\n",
       "      <td>-0.798959</td>\n",
       "      <td>1.001305</td>\n",
       "      <td>0.691063</td>\n",
       "      <td>0.193017</td>\n",
       "      <td>-0.804408</td>\n",
       "      <td>0.633024</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.668045</td>\n",
       "      <td>1.188825</td>\n",
       "      <td>0.788128</td>\n",
       "      <td>-1.885749</td>\n",
       "      <td>0.278859</td>\n",
       "      <td>-0.054479</td>\n",
       "      <td>-2.100279</td>\n",
       "      <td>1.034174</td>\n",
       "      <td>-1.231385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.174949</td>\n",
       "      <td>1.189296</td>\n",
       "      <td>-0.927771</td>\n",
       "      <td>0.257538</td>\n",
       "      <td>-0.298800</td>\n",
       "      <td>1.077674</td>\n",
       "      <td>-0.749863</td>\n",
       "      <td>-0.397366</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>-0.734707</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.870219</td>\n",
       "      <td>-1.867665</td>\n",
       "      <td>-0.657096</td>\n",
       "      <td>-2.281700</td>\n",
       "      <td>0.161461</td>\n",
       "      <td>-1.713752</td>\n",
       "      <td>-0.332595</td>\n",
       "      <td>1.556750</td>\n",
       "      <td>0.761622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.164659</td>\n",
       "      <td>-0.700158</td>\n",
       "      <td>-0.188421</td>\n",
       "      <td>-0.743105</td>\n",
       "      <td>0.681166</td>\n",
       "      <td>1.100095</td>\n",
       "      <td>0.149085</td>\n",
       "      <td>-0.199905</td>\n",
       "      <td>-0.679346</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997326</td>\n",
       "      <td>-0.818119</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>-0.603537</td>\n",
       "      <td>1.588145</td>\n",
       "      <td>-0.283121</td>\n",
       "      <td>-0.996231</td>\n",
       "      <td>0.791162</td>\n",
       "      <td>0.468696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.584759</td>\n",
       "      <td>-1.071538</td>\n",
       "      <td>-2.043505</td>\n",
       "      <td>0.484414</td>\n",
       "      <td>0.151943</td>\n",
       "      <td>-0.082056</td>\n",
       "      <td>0.598946</td>\n",
       "      <td>-0.408808</td>\n",
       "      <td>0.550904</td>\n",
       "      <td>-0.182296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>-2.751466</td>\n",
       "      <td>-3.539840</td>\n",
       "      <td>-0.875378</td>\n",
       "      <td>0.360259</td>\n",
       "      <td>-0.244792</td>\n",
       "      <td>-0.170450</td>\n",
       "      <td>1.971528</td>\n",
       "      <td>1.845870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.368351</td>\n",
       "      <td>-1.080365</td>\n",
       "      <td>-3.706199</td>\n",
       "      <td>0.516378</td>\n",
       "      <td>-0.244941</td>\n",
       "      <td>1.347507</td>\n",
       "      <td>1.047686</td>\n",
       "      <td>1.546216</td>\n",
       "      <td>3.523230</td>\n",
       "      <td>-1.889053</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.064988</td>\n",
       "      <td>0.504453</td>\n",
       "      <td>-0.026259</td>\n",
       "      <td>0.093963</td>\n",
       "      <td>2.178278</td>\n",
       "      <td>-1.309577</td>\n",
       "      <td>-2.458808</td>\n",
       "      <td>1.464417</td>\n",
       "      <td>-0.882024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Jud_0     Jud_1     Jud_2     Jud_3     Jud_4     Jud_5     Jud_6  \\\n",
       "0 -0.709013 -0.487325 -1.056965  0.818804 -0.798959  1.001305  0.691063   \n",
       "1  0.174949  1.189296 -0.927771  0.257538 -0.298800  1.077674 -0.749863   \n",
       "2  0.164659 -0.700158 -0.188421 -0.743105  0.681166  1.100095  0.149085   \n",
       "3 -0.584759 -1.071538 -2.043505  0.484414  0.151943 -0.082056  0.598946   \n",
       "4 -1.368351 -1.080365 -3.706199  0.516378 -0.244941  1.347507  1.047686   \n",
       "\n",
       "      Jud_7     Jud_8     Jud_9  ...   Jud_141   Jud_142   Jud_143   Jud_144  \\\n",
       "0  0.193017 -0.804408  0.633024  ... -1.668045  1.188825  0.788128 -1.885749   \n",
       "1 -0.397366  0.008756 -0.734707  ... -1.870219 -1.867665 -0.657096 -2.281700   \n",
       "2 -0.199905 -0.679346  0.046218  ...  0.997326 -0.818119  0.844203 -0.603537   \n",
       "3 -0.408808  0.550904 -0.182296  ...  0.004010 -2.751466 -3.539840 -0.875378   \n",
       "4  1.546216  3.523230 -1.889053  ... -4.064988  0.504453 -0.026259  0.093963   \n",
       "\n",
       "    Jud_145   Jud_146   Jud_147   Jud_148   Jud_149  harsh  \n",
       "0  0.278859 -0.054479 -2.100279  1.034174 -1.231385      0  \n",
       "1  0.161461 -1.713752 -0.332595  1.556750  0.761622      1  \n",
       "2  1.588145 -0.283121 -0.996231  0.791162  0.468696      0  \n",
       "3  0.360259 -0.244792 -0.170450  1.971528  1.845870      0  \n",
       "4  2.178278 -1.309577 -2.458808  1.464417 -0.882024      1  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3 = pd.concat((model_vec,second_stage_model_data[second_stage_model_data.columns[:-1]]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jud_0</th>\n",
       "      <th>Jud_1</th>\n",
       "      <th>Jud_2</th>\n",
       "      <th>Jud_3</th>\n",
       "      <th>Jud_4</th>\n",
       "      <th>Jud_5</th>\n",
       "      <th>Jud_6</th>\n",
       "      <th>Jud_7</th>\n",
       "      <th>Jud_8</th>\n",
       "      <th>Jud_9</th>\n",
       "      <th>...</th>\n",
       "      <th>fact_emb_44</th>\n",
       "      <th>fact_emb_45</th>\n",
       "      <th>fact_emb_46</th>\n",
       "      <th>fact_emb_47</th>\n",
       "      <th>fact_emb_48</th>\n",
       "      <th>fact_emb_49</th>\n",
       "      <th>judgement_pred</th>\n",
       "      <th>gov_pet</th>\n",
       "      <th>gov_resp</th>\n",
       "      <th>crime_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.709013</td>\n",
       "      <td>-0.487325</td>\n",
       "      <td>-1.056965</td>\n",
       "      <td>0.818804</td>\n",
       "      <td>-0.798959</td>\n",
       "      <td>1.001305</td>\n",
       "      <td>0.691063</td>\n",
       "      <td>0.193017</td>\n",
       "      <td>-0.804408</td>\n",
       "      <td>0.633024</td>\n",
       "      <td>...</td>\n",
       "      <td>2.563970</td>\n",
       "      <td>0.277645</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>1.128461</td>\n",
       "      <td>1.312803</td>\n",
       "      <td>-2.323720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.174949</td>\n",
       "      <td>1.189296</td>\n",
       "      <td>-0.927771</td>\n",
       "      <td>0.257538</td>\n",
       "      <td>-0.298800</td>\n",
       "      <td>1.077674</td>\n",
       "      <td>-0.749863</td>\n",
       "      <td>-0.397366</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>-0.734707</td>\n",
       "      <td>...</td>\n",
       "      <td>1.598934</td>\n",
       "      <td>0.472292</td>\n",
       "      <td>0.188702</td>\n",
       "      <td>-1.014126</td>\n",
       "      <td>2.751991</td>\n",
       "      <td>-1.364089</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.164659</td>\n",
       "      <td>-0.700158</td>\n",
       "      <td>-0.188421</td>\n",
       "      <td>-0.743105</td>\n",
       "      <td>0.681166</td>\n",
       "      <td>1.100095</td>\n",
       "      <td>0.149085</td>\n",
       "      <td>-0.199905</td>\n",
       "      <td>-0.679346</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>...</td>\n",
       "      <td>3.449621</td>\n",
       "      <td>0.274740</td>\n",
       "      <td>-1.984469</td>\n",
       "      <td>-1.442404</td>\n",
       "      <td>-0.851224</td>\n",
       "      <td>1.276552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.584759</td>\n",
       "      <td>-1.071538</td>\n",
       "      <td>-2.043505</td>\n",
       "      <td>0.484414</td>\n",
       "      <td>0.151943</td>\n",
       "      <td>-0.082056</td>\n",
       "      <td>0.598946</td>\n",
       "      <td>-0.408808</td>\n",
       "      <td>0.550904</td>\n",
       "      <td>-0.182296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914630</td>\n",
       "      <td>-0.420852</td>\n",
       "      <td>-0.492278</td>\n",
       "      <td>-2.264972</td>\n",
       "      <td>3.601571</td>\n",
       "      <td>0.398855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.368351</td>\n",
       "      <td>-1.080365</td>\n",
       "      <td>-3.706199</td>\n",
       "      <td>0.516378</td>\n",
       "      <td>-0.244941</td>\n",
       "      <td>1.347507</td>\n",
       "      <td>1.047686</td>\n",
       "      <td>1.546216</td>\n",
       "      <td>3.523230</td>\n",
       "      <td>-1.889053</td>\n",
       "      <td>...</td>\n",
       "      <td>3.059956</td>\n",
       "      <td>1.365849</td>\n",
       "      <td>3.039275</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>0.342930</td>\n",
       "      <td>3.686197</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Jud_0     Jud_1     Jud_2     Jud_3     Jud_4     Jud_5     Jud_6  \\\n",
       "0 -0.709013 -0.487325 -1.056965  0.818804 -0.798959  1.001305  0.691063   \n",
       "1  0.174949  1.189296 -0.927771  0.257538 -0.298800  1.077674 -0.749863   \n",
       "2  0.164659 -0.700158 -0.188421 -0.743105  0.681166  1.100095  0.149085   \n",
       "3 -0.584759 -1.071538 -2.043505  0.484414  0.151943 -0.082056  0.598946   \n",
       "4 -1.368351 -1.080365 -3.706199  0.516378 -0.244941  1.347507  1.047686   \n",
       "\n",
       "      Jud_7     Jud_8     Jud_9  ...  fact_emb_44  fact_emb_45  fact_emb_46  \\\n",
       "0  0.193017 -0.804408  0.633024  ...     2.563970     0.277645     0.018563   \n",
       "1 -0.397366  0.008756 -0.734707  ...     1.598934     0.472292     0.188702   \n",
       "2 -0.199905 -0.679346  0.046218  ...     3.449621     0.274740    -1.984469   \n",
       "3 -0.408808  0.550904 -0.182296  ...     0.914630    -0.420852    -0.492278   \n",
       "4  1.546216  3.523230 -1.889053  ...     3.059956     1.365849     3.039275   \n",
       "\n",
       "   fact_emb_47  fact_emb_48  fact_emb_49  judgement_pred  gov_pet  gov_resp  \\\n",
       "0     1.128461     1.312803    -2.323720               0      0.0       1.0   \n",
       "1    -1.014126     2.751991    -1.364089               1      0.0       0.0   \n",
       "2    -1.442404    -0.851224     1.276552               0      0.0       1.0   \n",
       "3    -2.264972     3.601571     0.398855               0      0.0       1.0   \n",
       "4    -0.088997     0.342930     3.686197               1      0.0       0.0   \n",
       "\n",
       "   crime_rate  \n",
       "0        92.5  \n",
       "1        92.5  \n",
       "2        92.5  \n",
       "3        92.5  \n",
       "4        92.5  \n",
       "\n",
       "[5 rows x 205 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3.to_csv(\"IV_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = pd.concat((model_vec, model_data['harsh']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = sm.ols(formula=form, data=temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted2 = reg2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  harsh   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.034\n",
      "Method:                 Least Squares   F-statistic:                     8.365\n",
      "Date:                Thu, 13 May 2021   Prob (F-statistic):          2.21e-168\n",
      "Time:                        08:54:33   Log-Likelihood:                -17441.\n",
      "No. Observations:               31052   AIC:                         3.518e+04\n",
      "Df Residuals:                   30902   BIC:                         3.643e+04\n",
      "Df Model:                         149                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.3094      0.013     24.198      0.000       0.284       0.334\n",
      "Jud_1         -0.0056      0.004     -1.433      0.152      -0.013       0.002\n",
      "Jud_2          0.0004      0.004      0.105      0.917      -0.008       0.009\n",
      "Jud_3          0.0039      0.004      0.915      0.360      -0.004       0.012\n",
      "Jud_4         -0.0068      0.004     -1.775      0.076      -0.014       0.001\n",
      "Jud_5          0.0105      0.004      2.624      0.009       0.003       0.018\n",
      "Jud_6          0.0141      0.004      3.279      0.001       0.006       0.022\n",
      "Jud_7          0.0070      0.004      1.719      0.086      -0.001       0.015\n",
      "Jud_8         -0.0186      0.004     -4.426      0.000      -0.027      -0.010\n",
      "Jud_9         -0.0123      0.004     -2.745      0.006      -0.021      -0.004\n",
      "Jud_10        -0.0035      0.004     -0.838      0.402      -0.012       0.005\n",
      "Jud_11        -0.0024      0.004     -0.559      0.576      -0.011       0.006\n",
      "Jud_12         0.0086      0.004      2.364      0.018       0.001       0.016\n",
      "Jud_13         0.0026      0.004      0.661      0.509      -0.005       0.010\n",
      "Jud_14        -0.0050      0.004     -1.232      0.218      -0.013       0.003\n",
      "Jud_15        -0.0022      0.004     -0.548      0.583      -0.010       0.006\n",
      "Jud_16         0.0022      0.005      0.484      0.628      -0.007       0.011\n",
      "Jud_17        -0.0074      0.004     -1.902      0.057      -0.015       0.000\n",
      "Jud_18      6.715e-05      0.004      0.017      0.987      -0.008       0.008\n",
      "Jud_19         0.0004      0.004      0.097      0.923      -0.008       0.009\n",
      "Jud_20         0.0072      0.004      1.788      0.074      -0.001       0.015\n",
      "Jud_21         0.0019      0.004      0.474      0.636      -0.006       0.010\n",
      "Jud_22        -0.0097      0.004     -2.320      0.020      -0.018      -0.002\n",
      "Jud_23        -0.0112      0.004     -2.785      0.005      -0.019      -0.003\n",
      "Jud_24         0.0048      0.004      1.193      0.233      -0.003       0.013\n",
      "Jud_25         0.0013      0.004      0.322      0.747      -0.007       0.009\n",
      "Jud_26        -0.0059      0.004     -1.463      0.143      -0.014       0.002\n",
      "Jud_27        -0.0135      0.004     -3.444      0.001      -0.021      -0.006\n",
      "Jud_28         0.0139      0.004      3.458      0.001       0.006       0.022\n",
      "Jud_29        -0.0062      0.004     -1.485      0.138      -0.014       0.002\n",
      "Jud_30        -0.0063      0.004     -1.623      0.105      -0.014       0.001\n",
      "Jud_31         0.0109      0.004      2.997      0.003       0.004       0.018\n",
      "Jud_32        -0.0007      0.004     -0.188      0.851      -0.008       0.006\n",
      "Jud_33        -0.0113      0.004     -3.103      0.002      -0.019      -0.004\n",
      "Jud_34         0.0070      0.004      1.607      0.108      -0.002       0.016\n",
      "Jud_35         0.0003      0.004      0.080      0.936      -0.008       0.008\n",
      "Jud_36        -0.0011      0.004     -0.282      0.778      -0.009       0.007\n",
      "Jud_37         0.0008      0.004      0.209      0.834      -0.007       0.009\n",
      "Jud_38         0.0114      0.004      2.808      0.005       0.003       0.019\n",
      "Jud_39        -0.0044      0.004     -1.073      0.283      -0.012       0.004\n",
      "Jud_40         0.0088      0.004      1.958      0.050   -8.96e-06       0.018\n",
      "Jud_41         0.0112      0.004      2.875      0.004       0.004       0.019\n",
      "Jud_42         0.0035      0.004      0.904      0.366      -0.004       0.011\n",
      "Jud_43        -0.0066      0.004     -1.614      0.106      -0.015       0.001\n",
      "Jud_44         0.0093      0.004      2.232      0.026       0.001       0.017\n",
      "Jud_45         0.0008      0.004      0.194      0.846      -0.007       0.009\n",
      "Jud_46         0.0003      0.004      0.082      0.935      -0.007       0.008\n",
      "Jud_47        -0.0181      0.004     -4.737      0.000      -0.026      -0.011\n",
      "Jud_48         0.0007      0.004      0.165      0.869      -0.007       0.008\n",
      "Jud_49        -0.0020      0.004     -0.509      0.611      -0.010       0.006\n",
      "Jud_50         0.0170      0.004      4.513      0.000       0.010       0.024\n",
      "Jud_51         0.0016      0.004      0.391      0.696      -0.006       0.010\n",
      "Jud_52        -0.0086      0.004     -2.008      0.045      -0.017      -0.000\n",
      "Jud_53        -0.0036      0.004     -0.845      0.398      -0.012       0.005\n",
      "Jud_54         0.0022      0.004      0.577      0.564      -0.005       0.010\n",
      "Jud_55        -0.0013      0.004     -0.324      0.746      -0.009       0.007\n",
      "Jud_56        -0.0029      0.004     -0.659      0.510      -0.012       0.006\n",
      "Jud_57        -0.0025      0.004     -0.592      0.554      -0.011       0.006\n",
      "Jud_58        -0.0054      0.004     -1.248      0.212      -0.014       0.003\n",
      "Jud_59         0.0092      0.005      2.023      0.043       0.000       0.018\n",
      "Jud_60         0.0092      0.004      2.101      0.036       0.001       0.018\n",
      "Jud_61        -0.0099      0.004     -2.271      0.023      -0.018      -0.001\n",
      "Jud_62         0.0077      0.004      2.020      0.043       0.000       0.015\n",
      "Jud_63        -0.0073      0.004     -1.827      0.068      -0.015       0.001\n",
      "Jud_64        -0.0035      0.004     -0.834      0.404      -0.012       0.005\n",
      "Jud_65        -0.0039      0.004     -0.981      0.327      -0.012       0.004\n",
      "Jud_66         0.0173      0.005      3.621      0.000       0.008       0.027\n",
      "Jud_67         0.0073      0.004      1.816      0.069      -0.001       0.015\n",
      "Jud_68         0.0136      0.004      3.234      0.001       0.005       0.022\n",
      "Jud_69        -0.0013      0.004     -0.314      0.754      -0.010       0.007\n",
      "Jud_70         0.0058      0.004      1.437      0.151      -0.002       0.014\n",
      "Jud_71        -0.0043      0.004     -1.053      0.292      -0.012       0.004\n",
      "Jud_72        -0.0076      0.004     -1.810      0.070      -0.016       0.001\n",
      "Jud_73        -0.0140      0.004     -3.396      0.001      -0.022      -0.006\n",
      "Jud_74         0.0040      0.004      0.994      0.320      -0.004       0.012\n",
      "Jud_75         0.0004      0.004      0.099      0.921      -0.008       0.009\n",
      "Jud_76         0.0049      0.004      1.186      0.236      -0.003       0.013\n",
      "Jud_77        -0.0173      0.004     -4.294      0.000      -0.025      -0.009\n",
      "Jud_78         0.0056      0.004      1.374      0.169      -0.002       0.014\n",
      "Jud_79        -0.0027      0.004     -0.633      0.527      -0.011       0.006\n",
      "Jud_80         0.0071      0.004      1.754      0.079      -0.001       0.015\n",
      "Jud_81         0.0076      0.004      2.067      0.039       0.000       0.015\n",
      "Jud_82        -0.0067      0.004     -1.864      0.062      -0.014       0.000\n",
      "Jud_83        -0.0141      0.004     -3.748      0.000      -0.021      -0.007\n",
      "Jud_84         0.0099      0.004      2.216      0.027       0.001       0.019\n",
      "Jud_85        -0.0115      0.004     -2.808      0.005      -0.019      -0.003\n",
      "Jud_86        -0.0047      0.004     -1.169      0.242      -0.013       0.003\n",
      "Jud_87        -0.0015      0.004     -0.373      0.709      -0.010       0.006\n",
      "Jud_88        -0.0015      0.004     -0.368      0.713      -0.010       0.007\n",
      "Jud_89        -0.0111      0.004     -2.640      0.008      -0.019      -0.003\n",
      "Jud_90        -0.0054      0.005     -1.173      0.241      -0.015       0.004\n",
      "Jud_91        -0.0016      0.004     -0.396      0.692      -0.010       0.006\n",
      "Jud_92         0.0064      0.004      1.606      0.108      -0.001       0.014\n",
      "Jud_93        -0.0050      0.004     -1.206      0.228      -0.013       0.003\n",
      "Jud_94        -0.0018      0.004     -0.418      0.676      -0.010       0.007\n",
      "Jud_95         0.0060      0.004      1.427      0.154      -0.002       0.014\n",
      "Jud_96        -0.0011      0.004     -0.280      0.779      -0.009       0.007\n",
      "Jud_97        -0.0090      0.004     -2.292      0.022      -0.017      -0.001\n",
      "Jud_98        -0.0006      0.004     -0.153      0.878      -0.009       0.007\n",
      "Jud_99        -0.0009      0.004     -0.220      0.826      -0.009       0.007\n",
      "Jud_100        0.0063      0.004      1.659      0.097      -0.001       0.014\n",
      "Jud_101       -0.0005      0.004     -0.119      0.905      -0.008       0.007\n",
      "Jud_102       -0.0037      0.004     -0.872      0.383      -0.012       0.005\n",
      "Jud_103       -0.0121      0.004     -2.812      0.005      -0.020      -0.004\n",
      "Jud_104       -0.0080      0.004     -2.024      0.043      -0.016      -0.000\n",
      "Jud_105        0.0014      0.004      0.328      0.743      -0.007       0.009\n",
      "Jud_106        0.0105      0.004      2.377      0.017       0.002       0.019\n",
      "Jud_107        0.0051      0.004      1.215      0.224      -0.003       0.013\n",
      "Jud_108       -0.0022      0.004     -0.505      0.613      -0.011       0.006\n",
      "Jud_109       -0.0038      0.005     -0.830      0.406      -0.013       0.005\n",
      "Jud_110        0.0058      0.004      1.340      0.180      -0.003       0.014\n",
      "Jud_111       -0.0049      0.004     -1.124      0.261      -0.013       0.004\n",
      "Jud_112        0.0037      0.004      0.986      0.324      -0.004       0.011\n",
      "Jud_113       -0.0003      0.004     -0.066      0.947      -0.008       0.008\n",
      "Jud_114       -0.0041      0.004     -0.970      0.332      -0.012       0.004\n",
      "Jud_115        0.0003      0.004      0.085      0.932      -0.008       0.008\n",
      "Jud_116        0.0065      0.005      1.401      0.161      -0.003       0.016\n",
      "Jud_117        0.0024      0.004      0.608      0.543      -0.005       0.010\n",
      "Jud_118       -0.0013      0.004     -0.309      0.757      -0.009       0.007\n",
      "Jud_119       -0.0012      0.004     -0.289      0.772      -0.010       0.007\n",
      "Jud_120        0.0110      0.004      2.705      0.007       0.003       0.019\n",
      "Jud_121        0.0050      0.004      1.199      0.231      -0.003       0.013\n",
      "Jud_122       -0.0002      0.004     -0.041      0.967      -0.008       0.008\n",
      "Jud_123       -0.0104      0.004     -2.534      0.011      -0.019      -0.002\n",
      "Jud_124       -0.0003      0.004     -0.062      0.950      -0.008       0.008\n",
      "Jud_125       -0.0016      0.004     -0.374      0.709      -0.010       0.007\n",
      "Jud_126       -0.0009      0.004     -0.224      0.823      -0.009       0.007\n",
      "Jud_127       -0.0133      0.004     -3.254      0.001      -0.021      -0.005\n",
      "Jud_128        0.0118      0.004      2.901      0.004       0.004       0.020\n",
      "Jud_129       -0.0125      0.004     -2.986      0.003      -0.021      -0.004\n",
      "Jud_130        0.0060      0.004      1.496      0.135      -0.002       0.014\n",
      "Jud_131        0.0066      0.004      1.759      0.079      -0.001       0.014\n",
      "Jud_132       -0.0003      0.004     -0.096      0.923      -0.007       0.007\n",
      "Jud_133       -0.0062      0.004     -1.647      0.100      -0.014       0.001\n",
      "Jud_134        0.0064      0.004      1.447      0.148      -0.002       0.015\n",
      "Jud_135       -0.0050      0.004     -1.211      0.226      -0.013       0.003\n",
      "Jud_136        0.0010      0.004      0.248      0.804      -0.007       0.009\n",
      "Jud_137       -0.0028      0.004     -0.692      0.489      -0.011       0.005\n",
      "Jud_138        0.0039      0.004      0.935      0.350      -0.004       0.012\n",
      "Jud_139       -0.0077      0.004     -1.861      0.063      -0.016       0.000\n",
      "Jud_140        0.0093      0.005      2.027      0.043       0.000       0.018\n",
      "Jud_141        0.0021      0.004      0.535      0.593      -0.006       0.010\n",
      "Jud_142        0.0090      0.004      2.255      0.024       0.001       0.017\n",
      "Jud_143       -0.0099      0.004     -2.440      0.015      -0.018      -0.002\n",
      "Jud_144        0.0088      0.004      2.008      0.045       0.000       0.017\n",
      "Jud_145        0.0008      0.004      0.187      0.852      -0.007       0.009\n",
      "Jud_146       -0.0007      0.004     -0.168      0.867      -0.009       0.007\n",
      "Jud_147       -0.0100      0.004     -2.569      0.010      -0.018      -0.002\n",
      "Jud_148        0.0129      0.004      3.125      0.002       0.005       0.021\n",
      "Jud_149       -0.0072      0.004     -1.752      0.080      -0.015       0.001\n",
      "==============================================================================\n",
      "Omnibus:                     5131.224   Durbin-Watson:                   1.869\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6664.186\n",
      "Skew:                           1.097   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.418   Cond. No.                         32.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data[['Juridiction','Year']].to_csv(\"fe.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
